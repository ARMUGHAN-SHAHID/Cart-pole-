{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda2/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/armughan/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_placeholders(input_shape):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=[None,input_shape])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_hidden_layers(inputs,num_neurons_in_all_layers,activation_fn,initializer):\n",
    "    layer_inputs=inputs\n",
    "    for num_neurons in num_neurons_in_all_layers:\n",
    "        layer_outputs=tf.layers.dense(layer_inputs,num_neurons,activation=activation_fn,kernel_initializer=initializer)\n",
    "        layer_inputs=layer_outputs\n",
    "    return layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_loss(logits,targets,loss_fn):\n",
    "    entropies=loss_fn(labels=targets,logits=logits)\n",
    "#     loss=tf.reduce_mean(entropies)\n",
    "#     return loss\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gradients_and_optimizer(loss,learning_rate,optimizer_fn):\n",
    "    optimizer=optimizer_fn(learning_rate)\n",
    "    grads_and_vars=optimizer.compute_gradients(loss)\n",
    "    return optimizer,grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(optimizer,grads_and_vars):\n",
    "    grad_placeholders_list=[]\n",
    "    grads_and_vars_feed=[]\n",
    "    for grad,var in grads_and_vars:\n",
    "        grad_placeholder=tf.placeholder(tf.float32,shape=grad.get_shape())\n",
    "        grad_placeholders_list.append(grad_placeholder)\n",
    "        grads_and_vars_feed.append((grad_placeholder,var))\n",
    "    train_op=optimizer.apply_gradients(grads_and_vars_feed)\n",
    "    return grad_placeholders_list,grads_and_vars_feed,train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self,params):\n",
    "        input_shape=params['input_shape']\n",
    "        target_shape=params['target_shape']\n",
    "        num_outputs=params['num_outputs']\n",
    "        num_neurons_in_hidden_layers=params['num_neurons']\n",
    "        activation_fn=params.get('activation_fn',tf.nn.relu)\n",
    "        loss_fn=params['loss_fn']\n",
    "        learning_rate=params['learning_rate']\n",
    "        optimizer_fn=params['optimizer_fn']\n",
    "        logdir=params['logdir']\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        initializer_fn=tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.X=form_placeholders(input_shape)\n",
    "        last_hidden_output=form_hidden_layers(self.X,num_neurons_in_hidden_layers,activation_fn,initializer_fn)\n",
    "        \n",
    "        logits=tf.layers.dense(last_hidden_output,num_outputs,kernel_initializer=initializer_fn)\n",
    "        self.logits=logits\n",
    "        self.outputs=tf.nn.sigmoid(logits)\n",
    "        p_left_and_right=tf.concat(axis=1,values=[self.outputs,1-self.outputs])\n",
    "        self.action=tf.multinomial(tf.log(p_left_and_right),num_samples=1)\n",
    "        \n",
    "        targets=1-tf.to_float(self.action)\n",
    "        \n",
    "        self.entropies=form_loss(logits,targets,loss_fn)\n",
    "        self.optimizer,grads_and_vars=get_gradients_and_optimizer(self.entropies,learning_rate,optimizer_fn)\n",
    "        self.gradients=[grad for grad,variable in grads_and_vars]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.grad_placeholders_list=[]\n",
    "        self.grads_and_vars_feed=[]\n",
    "        for grad,var in grads_and_vars:\n",
    "            grad_placeholder=tf.placeholder(tf.float32,shape=grad.get_shape())\n",
    "            self.grad_placeholders_list.append(grad_placeholder)\n",
    "            self.grads_and_vars_feed.append((grad_placeholder,var))\n",
    "        self.train_op=self.optimizer.apply_gradients(self.grads_and_vars_feed)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.grad_placeholders_list,self.grads_and_vars_feed,self.train_op=update_weights(self.optimizer,grads_and_vars)\n",
    "        \n",
    "        self.initializer=tf.global_variables_initializer()\n",
    "        self.saver=tf.train.Saver()\n",
    "#         summ=tf.summary.scalar(self.entropies)\n",
    "#         self.summaries=tf.summary.merge_all()\n",
    "#         self.file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cumulative_discounted_rewards(rewards,discount_rate):#cumulates rewards for a single episode/game\n",
    "    disc_rewards=np.empty(len(rewards))\n",
    "    cum_rewards=0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cum_rewards=rewards[step]+cum_rewards*discount_rate\n",
    "        disc_rewards[step]=cum_rewards\n",
    "    return disc_rewards  #returning dicounted rewards(same shape as the rewards in the parameters )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_and_cumulate_rewards(all_rewards,discount_rate):#cumulates and normalizes rewards over many episodes/games\n",
    "    \n",
    "    all_discounted_rewards=[get_cumulative_discounted_rewards(episode_reward,discount_rate) for episode_reward in all_rewards]\n",
    "    flat_rewards=np.concatenate(all_discounted_rewards)\n",
    "    reward_mean=flat_rewards.mean()\n",
    "    reward_std=flat_rewards.std()\n",
    "    return [(discounted_episode_rewards-reward_mean)/float(reward_std) for discounted_episode_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'input_shape':4,\n",
    "    'target_shape':4,\n",
    "    'num_outputs':1,\n",
    "    'num_neurons':[4],\n",
    "    'activation_fn':tf.nn.elu,\n",
    "    'loss_fn':tf.nn.sigmoid_cross_entropy_with_logits,\n",
    "    'learning_rate':0.01,\n",
    "    'optimizer_fn':tf.train.AdamOptimizer,\n",
    "    'logdir':'/tf_logs_rnn/run/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model=ANN(params)\n",
    "# env=gym.make(\"CartPole-v0\")\n",
    "# n_iter=250\n",
    "# n_games_per_iter=10\n",
    "# n_steps_per_game=1000\n",
    "# discount_rate=0.95\n",
    "# savedir='/tmp/my_model_final.ckpt'\n",
    "# with tf.Session() as sess:\n",
    "# #     if os.path.isfile(savedir):\n",
    "#     print ('restoring model')\n",
    "#     model.saver.restore(sess,savedir)\n",
    "# #     else:\n",
    "# #     model.initializer.run()\n",
    "#     for i in range(n_iter):\n",
    "#         all_rewards=[]\n",
    "#         all_gradients=[]#will contain grads of diff vars for many steps of many games/episodes so size=vars*steps_in_game*num_games\n",
    "#         print ('current iteration '+str(i))\n",
    "        \n",
    "#         mean_entr=[]\n",
    "        \n",
    "#         for j in range(n_games_per_iter):\n",
    "#             current_episode_rewards=[]\n",
    "#             current_episode_grads=[]#will contain grads of diff variable for many steps of the current game so size=vars*no_of steps in this episode \n",
    "            \n",
    "#             obs=env.reset()\n",
    "#             for k in range(n_steps_per_game):\n",
    "#                 feed_dict={model.X:obs.reshape(1,params['input_shape'])}\n",
    "#                 action,grads,entropies=sess.run([model.action,model.gradients,model.entropies],feed_dict=feed_dict)\n",
    "# #                 print (entropies)\n",
    "#                 mean_entr.append(entropies)\n",
    "                \n",
    "#                 obs,reward,done,info=env.step(action[0][0])\n",
    "#                 current_episode_rewards.append(reward)\n",
    "#                 current_episode_grads.append(grads)\n",
    "#                 if done:\n",
    "#                     break\n",
    "#             all_rewards.append(current_episode_rewards)\n",
    "#             all_gradients.append(current_episode_grads)\n",
    "            \n",
    "#         #now we need to train/update model since the model has played   the game for n_games_per_iter \n",
    "#         all_normalized_rewards=normalize_and_cumulate_rewards(all_rewards,discount_rate) #normalizing the rewards so that the chances of a good action getting a bad score are reduced\n",
    "#         feed_dict={}#for supplying model with the mean gradients multiplied by the rewards \n",
    "#         for var_index,grad_placeholder in enumerate(model.grad_placeholders_list):\n",
    "#             mean_grads=np.mean(\n",
    "#             [reward*all_gradients[game_index][step][var_index] for game_index,game_rewards in enumerate(all_rewards) for step,reward in enumerate(game_rewards)]\n",
    "#             ,axis=0)\n",
    "#             feed_dict[grad_placeholder]=mean_grads\n",
    "#         sess.run([model.train_op],feed_dict=feed_dict)\n",
    "#         model.saver.save(sess,savedir)\n",
    "#         print ('entropy =')\n",
    "#         print (np.mean(np.array(mean_entr)))\n",
    "        \n",
    "        \n",
    "#     n_steps=1000\n",
    "#     obs=env.reset()\n",
    "#     for i in range(n_steps):\n",
    "#         feed_dict={model.X:obs.reshape(1,params['input_shape'])}\n",
    "#         outputs=sess.run(model.outputs,feed_dict=feed_dict)\n",
    "#         action=0 if outputs>=0.5 else 1\n",
    "#         obs,reward,done,info=env.step(action)\n",
    "#         env.render()\n",
    "#         print ('step no '+str(i))\n",
    "#         if done:\n",
    "#             print ('lost')\n",
    "#             break   \n",
    "# #     model.file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "current iteration 0\n",
      "entropy =\n",
      "0.6507775\n",
      "current iteration 1\n",
      "entropy =\n",
      "0.65463793\n",
      "current iteration 2\n",
      "entropy =\n",
      "0.65546\n",
      "current iteration 3\n",
      "entropy =\n",
      "0.6974031\n",
      "current iteration 4\n",
      "entropy =\n",
      "0.66370595\n",
      "current iteration 5\n",
      "entropy =\n",
      "0.69489026\n",
      "current iteration 6\n",
      "entropy =\n",
      "0.64200616\n",
      "current iteration 7\n",
      "entropy =\n",
      "0.67697936\n",
      "current iteration 8\n",
      "entropy =\n",
      "0.648913\n",
      "current iteration 9\n",
      "entropy =\n",
      "0.6852597\n",
      "current iteration 10\n",
      "entropy =\n",
      "0.68037456\n",
      "current iteration 11\n",
      "entropy =\n",
      "0.6854181\n",
      "current iteration 12\n",
      "entropy =\n",
      "0.6367241\n",
      "current iteration 13\n",
      "entropy =\n",
      "0.68210673\n",
      "current iteration 14\n",
      "entropy =\n",
      "0.68074423\n",
      "current iteration 15\n",
      "entropy =\n",
      "0.688564\n",
      "current iteration 16\n",
      "entropy =\n",
      "0.6774279\n",
      "current iteration 17\n",
      "entropy =\n",
      "0.67497677\n",
      "current iteration 18\n",
      "entropy =\n",
      "0.66992277\n",
      "current iteration 19\n",
      "entropy =\n",
      "0.68276423\n",
      "current iteration 20\n",
      "entropy =\n",
      "0.68212676\n",
      "current iteration 21\n",
      "entropy =\n",
      "0.6930197\n",
      "current iteration 22\n",
      "entropy =\n",
      "0.6638119\n",
      "current iteration 23\n",
      "entropy =\n",
      "0.67666537\n",
      "current iteration 24\n",
      "entropy =\n",
      "0.68553936\n",
      "current iteration 25\n",
      "entropy =\n",
      "0.67808133\n",
      "current iteration 26\n",
      "entropy =\n",
      "0.670329\n",
      "current iteration 27\n",
      "entropy =\n",
      "0.6610521\n",
      "current iteration 28\n",
      "entropy =\n",
      "0.6622594\n",
      "current iteration 29\n",
      "entropy =\n",
      "0.65733653\n",
      "current iteration 30\n",
      "entropy =\n",
      "0.6626185\n",
      "current iteration 31\n",
      "entropy =\n",
      "0.66545343\n",
      "current iteration 32\n",
      "entropy =\n",
      "0.66789705\n",
      "current iteration 33\n",
      "entropy =\n",
      "0.66294086\n",
      "current iteration 34\n",
      "entropy =\n",
      "0.6488589\n",
      "current iteration 35\n",
      "entropy =\n",
      "0.6556108\n",
      "current iteration 36\n",
      "entropy =\n",
      "0.6436442\n",
      "current iteration 37\n",
      "entropy =\n",
      "0.6511166\n",
      "current iteration 38\n",
      "entropy =\n",
      "0.6798531\n",
      "current iteration 39\n",
      "entropy =\n",
      "0.64700866\n",
      "current iteration 40\n",
      "entropy =\n",
      "0.6384809\n",
      "current iteration 41\n",
      "entropy =\n",
      "0.644437\n",
      "current iteration 42\n",
      "entropy =\n",
      "0.6314809\n",
      "current iteration 43\n",
      "entropy =\n",
      "0.6384032\n",
      "current iteration 44\n",
      "entropy =\n",
      "0.6533834\n",
      "current iteration 45\n",
      "entropy =\n",
      "0.63684624\n",
      "current iteration 46\n",
      "entropy =\n",
      "0.6305671\n",
      "current iteration 47\n",
      "entropy =\n",
      "0.6298658\n",
      "current iteration 48\n",
      "entropy =\n",
      "0.6279714\n",
      "current iteration 49\n",
      "entropy =\n",
      "0.64539707\n",
      "current iteration 50\n",
      "entropy =\n",
      "0.623409\n",
      "current iteration 51\n",
      "entropy =\n",
      "0.6272778\n",
      "current iteration 52\n",
      "entropy =\n",
      "0.63685614\n",
      "current iteration 53\n",
      "entropy =\n",
      "0.6196402\n",
      "current iteration 54\n",
      "entropy =\n",
      "0.62494683\n",
      "current iteration 55\n",
      "entropy =\n",
      "0.6290161\n",
      "current iteration 56\n",
      "entropy =\n",
      "0.63102674\n",
      "current iteration 57\n",
      "entropy =\n",
      "0.62537676\n",
      "current iteration 58\n",
      "entropy =\n",
      "0.6312204\n",
      "current iteration 59\n",
      "entropy =\n",
      "0.61080164\n",
      "current iteration 60\n",
      "entropy =\n",
      "0.6235436\n",
      "current iteration 61\n",
      "entropy =\n",
      "0.61373925\n",
      "current iteration 62\n",
      "entropy =\n",
      "0.6089585\n",
      "current iteration 63\n",
      "entropy =\n",
      "0.62573975\n",
      "current iteration 64\n",
      "entropy =\n",
      "0.6129282\n",
      "current iteration 65\n",
      "entropy =\n",
      "0.6076988\n",
      "current iteration 66\n",
      "entropy =\n",
      "0.60928375\n",
      "current iteration 67\n",
      "entropy =\n",
      "0.6146458\n",
      "current iteration 68\n",
      "entropy =\n",
      "0.6184993\n",
      "current iteration 69\n",
      "entropy =\n",
      "0.6042629\n",
      "current iteration 70\n",
      "entropy =\n",
      "0.60993797\n",
      "current iteration 71\n",
      "entropy =\n",
      "0.6149393\n",
      "current iteration 72\n",
      "entropy =\n",
      "0.6229293\n",
      "current iteration 73\n",
      "entropy =\n",
      "0.6043306\n",
      "current iteration 74\n",
      "entropy =\n",
      "0.6091238\n",
      "current iteration 75\n",
      "entropy =\n",
      "0.6070104\n",
      "current iteration 76\n",
      "entropy =\n",
      "0.60851216\n",
      "current iteration 77\n",
      "entropy =\n",
      "0.6111223\n",
      "current iteration 78\n",
      "entropy =\n",
      "0.60875696\n",
      "current iteration 79\n",
      "entropy =\n",
      "0.6025048\n",
      "current iteration 80\n",
      "entropy =\n",
      "0.60268945\n",
      "current iteration 81\n",
      "entropy =\n",
      "0.60709804\n",
      "current iteration 82\n",
      "entropy =\n",
      "0.60650337\n",
      "current iteration 83\n",
      "entropy =\n",
      "0.5948552\n",
      "current iteration 84\n",
      "entropy =\n",
      "0.59505004\n",
      "current iteration 85\n",
      "entropy =\n",
      "0.6044269\n",
      "current iteration 86\n",
      "entropy =\n",
      "0.60873884\n",
      "current iteration 87\n",
      "entropy =\n",
      "0.596642\n",
      "current iteration 88\n",
      "entropy =\n",
      "0.5981812\n",
      "current iteration 89\n",
      "entropy =\n",
      "0.5960201\n",
      "current iteration 90\n",
      "entropy =\n",
      "0.60053957\n",
      "current iteration 91\n",
      "entropy =\n",
      "0.5916353\n",
      "current iteration 92\n",
      "entropy =\n",
      "0.58916026\n",
      "current iteration 93\n",
      "entropy =\n",
      "0.5989375\n",
      "current iteration 94\n",
      "entropy =\n",
      "0.5875356\n",
      "current iteration 95\n",
      "entropy =\n",
      "0.5893441\n",
      "current iteration 96\n",
      "entropy =\n",
      "0.58967394\n",
      "current iteration 97\n",
      "entropy =\n",
      "0.59540915\n",
      "current iteration 98\n",
      "entropy =\n",
      "0.58467317\n",
      "current iteration 99\n",
      "entropy =\n",
      "0.59146094\n",
      "current iteration 100\n",
      "entropy =\n",
      "0.5924372\n",
      "current iteration 101\n",
      "entropy =\n",
      "0.5963163\n",
      "current iteration 102\n",
      "entropy =\n",
      "0.60569316\n",
      "current iteration 103\n",
      "entropy =\n",
      "0.5862487\n",
      "current iteration 104\n",
      "entropy =\n",
      "0.5951169\n",
      "current iteration 105\n",
      "entropy =\n",
      "0.5929122\n",
      "current iteration 106\n",
      "entropy =\n",
      "0.5862091\n",
      "current iteration 107\n",
      "entropy =\n",
      "0.58524483\n",
      "current iteration 108\n",
      "entropy =\n",
      "0.5915206\n",
      "current iteration 109\n",
      "entropy =\n",
      "0.5774209\n",
      "current iteration 110\n",
      "entropy =\n",
      "0.5826104\n",
      "current iteration 111\n",
      "entropy =\n",
      "0.5906574\n",
      "current iteration 112\n",
      "entropy =\n",
      "0.59104884\n",
      "current iteration 113\n",
      "entropy =\n",
      "0.5908814\n",
      "current iteration 114\n",
      "entropy =\n",
      "0.5808934\n",
      "current iteration 115\n",
      "entropy =\n",
      "0.5882329\n",
      "current iteration 116\n",
      "entropy =\n",
      "0.5836849\n",
      "current iteration 117\n",
      "entropy =\n",
      "0.5886574\n",
      "current iteration 118\n",
      "entropy =\n",
      "0.57662475\n",
      "current iteration 119\n",
      "entropy =\n",
      "0.58689743\n",
      "current iteration 120\n",
      "entropy =\n",
      "0.57327336\n",
      "current iteration 121\n",
      "entropy =\n",
      "0.57783854\n",
      "current iteration 122\n",
      "entropy =\n",
      "0.5923001\n",
      "current iteration 123\n",
      "entropy =\n",
      "0.58023447\n",
      "current iteration 124\n",
      "entropy =\n",
      "0.5786253\n",
      "current iteration 125\n",
      "entropy =\n",
      "0.59183234\n",
      "current iteration 126\n",
      "entropy =\n",
      "0.5763043\n",
      "current iteration 127\n",
      "entropy =\n",
      "0.57737255\n",
      "current iteration 128\n",
      "entropy =\n",
      "0.5765499\n",
      "current iteration 129\n",
      "entropy =\n",
      "0.5698318\n",
      "current iteration 130\n",
      "entropy =\n",
      "0.57778525\n",
      "current iteration 131\n",
      "entropy =\n",
      "0.57877463\n",
      "current iteration 132\n",
      "entropy =\n",
      "0.5665513\n",
      "current iteration 133\n",
      "entropy =\n",
      "0.57765007\n",
      "current iteration 134\n",
      "entropy =\n",
      "0.572358\n",
      "current iteration 135\n",
      "entropy =\n",
      "0.5787009\n",
      "current iteration 136\n",
      "entropy =\n",
      "0.5781743\n",
      "current iteration 137\n",
      "entropy =\n",
      "0.5822037\n",
      "current iteration 138\n",
      "entropy =\n",
      "0.56817126\n",
      "current iteration 139\n",
      "entropy =\n",
      "0.57454467\n",
      "current iteration 140\n",
      "entropy =\n",
      "0.5718477\n",
      "current iteration 141\n",
      "entropy =\n",
      "0.5748139\n",
      "current iteration 142\n",
      "entropy =\n",
      "0.5750476\n",
      "current iteration 143\n",
      "entropy =\n",
      "0.58017147\n",
      "current iteration 144\n",
      "entropy =\n",
      "0.5711614\n",
      "current iteration 145\n",
      "entropy =\n",
      "0.5694594\n",
      "current iteration 146\n",
      "entropy =\n",
      "0.56938666\n",
      "current iteration 147\n",
      "entropy =\n",
      "0.5746125\n",
      "current iteration 148\n",
      "entropy =\n",
      "0.56935525\n",
      "current iteration 149\n",
      "entropy =\n",
      "0.5718398\n",
      "current iteration 150\n",
      "entropy =\n",
      "0.57365686\n",
      "current iteration 151\n",
      "entropy =\n",
      "0.5680563\n",
      "current iteration 152\n",
      "entropy =\n",
      "0.564788\n",
      "current iteration 153\n",
      "entropy =\n",
      "0.57791483\n",
      "current iteration 154\n",
      "entropy =\n",
      "0.5702616\n",
      "current iteration 155\n",
      "entropy =\n",
      "0.55769765\n",
      "current iteration 156\n",
      "entropy =\n",
      "0.56300515\n",
      "current iteration 157\n",
      "entropy =\n",
      "0.5589223\n",
      "current iteration 158\n",
      "entropy =\n",
      "0.5746867\n",
      "current iteration 159\n",
      "entropy =\n",
      "0.56201124\n",
      "current iteration 160\n",
      "entropy =\n",
      "0.5601159\n",
      "current iteration 161\n",
      "entropy =\n",
      "0.56788325\n",
      "current iteration 162\n",
      "entropy =\n",
      "0.5656412\n",
      "current iteration 163\n",
      "entropy =\n",
      "0.5780562\n",
      "current iteration 164\n",
      "entropy =\n",
      "0.5670623\n",
      "current iteration 165\n",
      "entropy =\n",
      "0.56505686\n",
      "current iteration 166\n",
      "entropy =\n",
      "0.5655241\n",
      "current iteration 167\n",
      "entropy =\n",
      "0.5638761\n",
      "current iteration 168\n",
      "entropy =\n",
      "0.56938744\n",
      "current iteration 169\n",
      "entropy =\n",
      "0.56442064\n",
      "current iteration 170\n",
      "entropy =\n",
      "0.57153326\n",
      "current iteration 171\n",
      "entropy =\n",
      "0.5638093\n",
      "current iteration 172\n",
      "entropy =\n",
      "0.5581918\n",
      "current iteration 173\n",
      "entropy =\n",
      "0.5733705\n",
      "current iteration 174\n",
      "entropy =\n",
      "0.55686426\n",
      "current iteration 175\n",
      "entropy =\n",
      "0.5555417\n",
      "current iteration 176\n",
      "entropy =\n",
      "0.5675215\n",
      "current iteration 177\n",
      "entropy =\n",
      "0.55650795\n",
      "current iteration 178\n",
      "entropy =\n",
      "0.5692812\n",
      "current iteration 179\n",
      "entropy =\n",
      "0.5603218\n",
      "current iteration 180\n",
      "entropy =\n",
      "0.5609141\n",
      "current iteration 181\n",
      "entropy =\n",
      "0.5604809\n",
      "current iteration 182\n",
      "entropy =\n",
      "0.5592262\n",
      "current iteration 183\n",
      "entropy =\n",
      "0.5589109\n",
      "current iteration 184\n",
      "entropy =\n",
      "0.5631098\n",
      "current iteration 185\n",
      "entropy =\n",
      "0.55702585\n",
      "current iteration 186\n",
      "entropy =\n",
      "0.566482\n",
      "current iteration 187\n",
      "entropy =\n",
      "0.57588\n",
      "current iteration 188\n",
      "entropy =\n",
      "0.56292415\n",
      "current iteration 189\n",
      "entropy =\n",
      "0.55455136\n",
      "current iteration 190\n",
      "entropy =\n",
      "0.5675849\n",
      "current iteration 191\n",
      "entropy =\n",
      "0.570071\n",
      "current iteration 192\n",
      "entropy =\n",
      "0.5630742\n",
      "current iteration 193\n",
      "entropy =\n",
      "0.5571134\n",
      "current iteration 194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy =\n",
      "0.5604634\n",
      "current iteration 195\n",
      "entropy =\n",
      "0.56017524\n",
      "current iteration 196\n",
      "entropy =\n",
      "0.5621141\n",
      "current iteration 197\n",
      "entropy =\n",
      "0.55160683\n",
      "current iteration 198\n",
      "entropy =\n",
      "0.5657002\n",
      "current iteration 199\n",
      "entropy =\n",
      "0.55812114\n",
      "current iteration 200\n",
      "entropy =\n",
      "0.55764073\n",
      "current iteration 201\n",
      "entropy =\n",
      "0.5613217\n",
      "current iteration 202\n",
      "entropy =\n",
      "0.5773436\n",
      "current iteration 203\n",
      "entropy =\n",
      "0.55674505\n",
      "current iteration 204\n",
      "entropy =\n",
      "0.5622384\n",
      "current iteration 205\n",
      "entropy =\n",
      "0.5667107\n",
      "current iteration 206\n",
      "entropy =\n",
      "0.5589674\n",
      "current iteration 207\n",
      "entropy =\n",
      "0.5662775\n",
      "current iteration 208\n",
      "entropy =\n",
      "0.56300884\n",
      "current iteration 209\n",
      "entropy =\n",
      "0.55630255\n",
      "current iteration 210\n",
      "entropy =\n",
      "0.56875616\n",
      "current iteration 211\n",
      "entropy =\n",
      "0.5704565\n",
      "current iteration 212\n",
      "entropy =\n",
      "0.56583685\n",
      "current iteration 213\n",
      "entropy =\n",
      "0.5670971\n",
      "current iteration 214\n",
      "entropy =\n",
      "0.56933767\n",
      "current iteration 215\n",
      "entropy =\n",
      "0.5558031\n",
      "current iteration 216\n",
      "entropy =\n",
      "0.5540253\n",
      "current iteration 217\n",
      "entropy =\n",
      "0.56090236\n",
      "current iteration 218\n",
      "entropy =\n",
      "0.5573555\n",
      "current iteration 219\n",
      "entropy =\n",
      "0.56084764\n",
      "current iteration 220\n",
      "entropy =\n",
      "0.5531214\n",
      "current iteration 221\n",
      "entropy =\n",
      "0.5524155\n",
      "current iteration 222\n",
      "entropy =\n",
      "0.5558844\n",
      "current iteration 223\n",
      "entropy =\n",
      "0.5634871\n",
      "current iteration 224\n",
      "entropy =\n",
      "0.55877876\n",
      "current iteration 225\n",
      "entropy =\n",
      "0.55255437\n",
      "current iteration 226\n",
      "entropy =\n",
      "0.5459437\n",
      "current iteration 227\n",
      "entropy =\n",
      "0.5494035\n",
      "current iteration 228\n",
      "entropy =\n",
      "0.5702664\n",
      "current iteration 229\n",
      "entropy =\n",
      "0.55202466\n",
      "current iteration 230\n",
      "entropy =\n",
      "0.553014\n",
      "current iteration 231\n",
      "entropy =\n",
      "0.55765915\n",
      "current iteration 232\n",
      "entropy =\n",
      "0.55709785\n",
      "current iteration 233\n",
      "entropy =\n",
      "0.54670477\n",
      "current iteration 234\n",
      "entropy =\n",
      "0.5509529\n",
      "current iteration 235\n",
      "entropy =\n",
      "0.55050707\n",
      "current iteration 236\n",
      "entropy =\n",
      "0.5458599\n",
      "current iteration 237\n",
      "entropy =\n",
      "0.5567189\n",
      "current iteration 238\n",
      "entropy =\n",
      "0.5474435\n",
      "current iteration 239\n",
      "entropy =\n",
      "0.541866\n",
      "current iteration 240\n",
      "entropy =\n",
      "0.5516957\n",
      "current iteration 241\n",
      "entropy =\n",
      "0.5608099\n",
      "current iteration 242\n",
      "entropy =\n",
      "0.54774266\n",
      "current iteration 243\n",
      "entropy =\n",
      "0.55877817\n",
      "current iteration 244\n",
      "entropy =\n",
      "0.5488802\n",
      "current iteration 245\n",
      "entropy =\n",
      "0.54749465\n",
      "current iteration 246\n",
      "entropy =\n",
      "0.546985\n",
      "current iteration 247\n",
      "entropy =\n",
      "0.5578098\n",
      "current iteration 248\n",
      "entropy =\n",
      "0.5497445\n",
      "current iteration 249\n",
      "entropy =\n",
      "0.5503071\n",
      "step no 0\n",
      "step no 1\n",
      "step no 2\n",
      "step no 3\n",
      "step no 4\n",
      "step no 5\n",
      "step no 6\n",
      "step no 7\n",
      "step no 8\n",
      "step no 9\n",
      "step no 10\n",
      "step no 11\n",
      "step no 12\n",
      "step no 13\n",
      "step no 14\n",
      "step no 15\n",
      "step no 16\n",
      "step no 17\n",
      "step no 18\n",
      "step no 19\n",
      "step no 20\n",
      "step no 21\n",
      "step no 22\n",
      "step no 23\n",
      "step no 24\n",
      "step no 25\n",
      "step no 26\n",
      "step no 27\n",
      "step no 28\n",
      "step no 29\n",
      "step no 30\n",
      "step no 31\n",
      "step no 32\n",
      "step no 33\n",
      "step no 34\n",
      "step no 35\n",
      "step no 36\n",
      "step no 37\n",
      "step no 38\n",
      "step no 39\n",
      "step no 40\n",
      "step no 41\n",
      "step no 42\n",
      "step no 43\n",
      "step no 44\n",
      "step no 45\n",
      "step no 46\n",
      "step no 47\n",
      "step no 48\n",
      "step no 49\n",
      "step no 50\n",
      "step no 51\n",
      "step no 52\n",
      "step no 53\n",
      "step no 54\n",
      "step no 55\n",
      "step no 56\n",
      "step no 57\n",
      "step no 58\n",
      "step no 59\n",
      "step no 60\n",
      "step no 61\n",
      "step no 62\n",
      "step no 63\n",
      "step no 64\n",
      "step no 65\n",
      "step no 66\n",
      "step no 67\n",
      "step no 68\n",
      "step no 69\n",
      "step no 70\n",
      "step no 71\n",
      "step no 72\n",
      "step no 73\n",
      "step no 74\n",
      "step no 75\n",
      "step no 76\n",
      "step no 77\n",
      "step no 78\n",
      "step no 79\n",
      "step no 80\n",
      "step no 81\n",
      "step no 82\n",
      "step no 83\n",
      "step no 84\n",
      "step no 85\n",
      "step no 86\n",
      "step no 87\n",
      "step no 88\n",
      "step no 89\n",
      "step no 90\n",
      "step no 91\n",
      "step no 92\n",
      "step no 93\n",
      "step no 94\n",
      "step no 95\n",
      "step no 96\n",
      "step no 97\n",
      "step no 98\n",
      "step no 99\n",
      "step no 100\n",
      "step no 101\n",
      "step no 102\n",
      "step no 103\n",
      "step no 104\n",
      "step no 105\n",
      "step no 106\n",
      "step no 107\n",
      "step no 108\n",
      "step no 109\n",
      "step no 110\n",
      "step no 111\n",
      "step no 112\n",
      "step no 113\n",
      "step no 114\n",
      "step no 115\n",
      "step no 116\n",
      "step no 117\n",
      "step no 118\n",
      "step no 119\n",
      "step no 120\n",
      "step no 121\n",
      "step no 122\n",
      "step no 123\n",
      "step no 124\n",
      "step no 125\n",
      "step no 126\n",
      "step no 127\n",
      "step no 128\n",
      "step no 129\n",
      "step no 130\n",
      "step no 131\n",
      "step no 132\n",
      "step no 133\n",
      "step no 134\n",
      "step no 135\n",
      "step no 136\n",
      "step no 137\n",
      "step no 138\n",
      "step no 139\n",
      "step no 140\n",
      "step no 141\n",
      "step no 142\n",
      "step no 143\n",
      "step no 144\n",
      "step no 145\n",
      "step no 146\n",
      "step no 147\n",
      "step no 148\n",
      "step no 149\n",
      "step no 150\n",
      "step no 151\n",
      "step no 152\n",
      "step no 153\n",
      "step no 154\n",
      "step no 155\n",
      "step no 156\n",
      "step no 157\n",
      "step no 158\n",
      "step no 159\n",
      "step no 160\n",
      "step no 161\n",
      "step no 162\n",
      "step no 163\n",
      "step no 164\n",
      "step no 165\n",
      "step no 166\n",
      "step no 167\n",
      "step no 168\n",
      "step no 169\n",
      "step no 170\n",
      "step no 171\n",
      "step no 172\n",
      "step no 173\n",
      "step no 174\n",
      "step no 175\n",
      "step no 176\n",
      "step no 177\n",
      "step no 178\n",
      "step no 179\n",
      "step no 180\n",
      "step no 181\n",
      "step no 182\n",
      "step no 183\n",
      "step no 184\n",
      "step no 185\n",
      "step no 186\n",
      "step no 187\n",
      "step no 188\n",
      "step no 189\n",
      "step no 190\n",
      "step no 191\n",
      "step no 192\n",
      "step no 193\n",
      "step no 194\n",
      "step no 195\n",
      "step no 196\n",
      "step no 197\n",
      "step no 198\n",
      "step no 199\n",
      "lost\n"
     ]
    }
   ],
   "source": [
    "#testing phase\n",
    "model=ANN(params)\n",
    "env=gym.make(\"CartPole-v0\")\n",
    "n_iter=250\n",
    "n_games_per_iter=10\n",
    "n_steps_per_game=1000\n",
    "discount_rate=0.95\n",
    "\n",
    "save_iterations=10# save the model every 10 training iterations\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model.initializer.run()\n",
    "    for iteration in range(n_iter):\n",
    "        all_rewards=[]# all sequences of raw rewards for each episode\n",
    "        all_gradients=[]# gradients saved at each step of each episode\n",
    "        mean_entr=[]\n",
    "        print ('current iteration '+str(iteration))\n",
    "        for game in range(n_games_per_iter):\n",
    "            current_rewards=[]# all raw rewards from the current episode\n",
    "            current_gradients=[]# all gradients from the current episode\n",
    "            obs=env.reset()\n",
    "            for step in range(n_steps_per_game):\n",
    "                action_val,gradients_val,entropies=sess.run(\n",
    "                [model.action,model.gradients,model.entropies],\n",
    "                feed_dict={model.X:obs.reshape(1,params['input_shape'])})# one obs\n",
    "                obs,reward,done,info=env.step(action_val[0][0])\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                mean_entr.append(entropies)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "        # At this point we have run the policy for 10 episodes, and we are\n",
    "        # ready for a policy update using the algorithm described earlier.\n",
    "        all_rewards=normalize_and_cumulate_rewards(all_rewards,discount_rate)\n",
    "        feed_dict={}\n",
    "        for var_index,grad_placeholder in enumerate(model.grad_placeholders_list):\n",
    "            # multiply the gradients by the action scores, and compute the mean\n",
    "            mean_gradients=np.mean(\n",
    "            [reward*all_gradients[game_index][step][var_index]\n",
    "            for game_index,rewards in enumerate(all_rewards)\n",
    "            for step,reward in enumerate(rewards)],\n",
    "            axis=0)\n",
    "            feed_dict[grad_placeholder]=mean_gradients\n",
    "        sess.run(model.train_op,feed_dict=feed_dict)\n",
    "        if iteration%save_iterations==0:\n",
    "            model.saver.save(sess,\"./my_policy_net_pg.ckpt\")\n",
    "        print ('entropy =')\n",
    "        print (np.mean(np.array(mean_entr)))\n",
    "        \n",
    "    n_steps=1000\n",
    "    obs=env.reset()\n",
    "    for i in range(n_steps):\n",
    "        feed_dict={model.X:obs.reshape(1,params['input_shape'])}\n",
    "        outputs_r=sess.run(model.outputs,feed_dict=feed_dict)\n",
    "        action=0 if outputs_r>=0.5 else 1\n",
    "        obs,reward,done,info=env.step(action)\n",
    "        env.render()\n",
    "        print ('step no '+str(i))\n",
    "        if done:\n",
    "            print ('lost')\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
